"""
Comprehensive test suite for Korean words to English translation.
Includes text, images, and audio clips for multimodal testing.
"""

import torch
import torch.nn as nn
import json
import os
import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import soundfile as sf
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
import matplotlib.pyplot as plt
import seaborn as sns

# Import custom modules
import sys
sys.path.append('.')
# Import the EnhancedTranslationModel from the training script
sys.path.append(os.path.join(os.path.dirname(__file__), '../../src/training'))
from train_optimized import EnhancedTranslationModel
from src.models.sp_tokenizer import SPTokenizer
from src.utils.metrics import BLEUScore, compute_translation_accuracy

@dataclass
class TestCase:
    """Test case data structure."""
    id: str
    korean_text: str
    expected_english: str
    category: str  # 'basic', 'intermediate', 'advanced', 'domain_specific'
    difficulty: int  # 1-5 scale
    audio_path: Optional[str] = None
    image_path: Optional[str] = None
    metadata: Optional[Dict] = None

class ComprehensiveTestSuite:
    """Comprehensive test suite for Korean-English translation."""
    
    def __init__(self, model_path: str, tokenizer_path: str, device: str = 'auto'):
        self.device = torch.device(device if device != 'auto' else 
                                  ('cuda' if torch.cuda.is_available() else 'cpu'))
        
        # Load model and tokenizer
        self.model = self._load_model(model_path)
        self.tokenizer = SPTokenizer(tokenizer_path)
        self.bleu_metric = BLEUScore()
        
        # Test results
        self.results = {}
        self.test_cases = []
        self.execution_times = []
        
        # Create test directories
        Path("tests/comprehensive/data").mkdir(parents=True, exist_ok=True)
        Path("tests/comprehensive/results").mkdir(parents=True, exist_ok=True)
        Path("tests/comprehensive/reports").mkdir(parents=True, exist_ok=True)
    
    def _load_model(self, model_path: str) -> nn.Module:
        """Load the trained model."""
        checkpoint = torch.load(model_path, map_location=self.device)
        
        # Initialize model with saved config
        config = checkpoint.get('config', {})
        model = EnhancedTranslationModel(
            vocab_size=config.get('vocab_size', 32000),
            d_model=config.get('d_model', 1024),
            n_heads=config.get('nhead', 16),
            n_layers=config.get('n_layers_student', 8),
            ff_dim=config.get('dim_feedforward', 4096),
            max_len=config.get('max_len', 128),
            pad_id=0
        ).to(self.device)
        
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        
        print(f"Model loaded: {sum(p.numel() for p in model.parameters()):,} parameters")
        return model
    
    def generate_test_cases(self) -> List[TestCase]:
        """Generate comprehensive test cases covering various categories."""
        test_cases = []
        
        # Basic vocabulary tests
        basic_cases = [
            ("ÏïàÎÖïÌïòÏÑ∏Ïöî", "Hello", 1),
            ("Í∞êÏÇ¨Ìï©ÎãàÎã§", "Thank you", 1),
            ("ÎØ∏ÏïàÌï©ÎãàÎã§", "Sorry", 1),
            ("ÎÑ§", "Yes", 1),
            ("ÏïÑÎãàÏöî", "No", 1),
            ("Î¨º", "Water", 1),
            ("Î∞•", "Rice", 1),
            ("ÌïôÍµê", "School", 2),
            ("Ïßë", "House", 1),
            ("Ï∞®", "Car", 1),
            ("Ï±Ö", "Book", 1),
            ("Ïª¥Ìì®ÌÑ∞", "Computer", 2),
            ("Ï†ÑÌôî", "Phone", 2),
            ("ÏãúÍ∞Ñ", "Time", 2),
            ("ÎÇ†Ïî®", "Weather", 2),
            ("Îèà", "Money", 1),
            ("ÏÇ¨Îûë", "Love", 2),
            ("ÏπúÍµ¨", "Friend", 1),
            ("Í∞ÄÏ°±", "Family", 2),
            ("Ïùº", "Work", 1),
        ]
        
        for i, (korean, english, difficulty) in enumerate(basic_cases):
            test_cases.append(TestCase(
                id=f"basic_{i:03d}",
                korean_text=korean,
                expected_english=english,
                category="basic",
                difficulty=difficulty
            ))
        
        # Intermediate phrase tests
        intermediate_cases = [
            ("Ïò§Îäò ÎÇ†Ïî®Í∞Ä Ïñ¥ÎïåÏöî?", "How is the weather today?", 3),
            ("Ï†êÏã¨ Î®πÏóàÏñ¥Ïöî?", "Did you eat lunch?", 3),
            ("Ïñ¥Îîî Í∞ÄÏÑ∏Ïöî?", "Where are you going?", 3),
            ("Î™á ÏãúÏòàÏöî?", "What time is it?", 3),
            ("ÏñºÎßàÏòàÏöî?", "How much is it?", 3),
            ("ÎèÑÏôÄÏ£ºÏÑ∏Ïöî", "Please help me", 3),
            ("Í∞ôÏù¥ Í∞àÎûòÏöî?", "Do you want to go together?", 3),
            ("Í∏∞Îã§Î†§Ï£ºÏÑ∏Ïöî", "Please wait", 3),
            ("Îπ®Î¶¨ ÏôÄÏ£ºÏÑ∏Ïöî", "Please come quickly", 3),
            ("Ï°∞Ïö©Ìûà Ìï¥Ï£ºÏÑ∏Ïöî", "Please be quiet", 3),
            ("Ï¶êÍ±∞Ïö¥ ÏãúÍ∞Ñ ÎêòÏÑ∏Ïöî", "Have a good time", 3),
            ("Îã§ÏùåÏóê Î¥êÏöî", "See you next time", 3),
            ("Ïò§ÎûúÎßåÏù¥ÏóêÏöî", "Long time no see", 3),
            ("Í±¥Í∞ïÌïòÏÑ∏Ïöî", "Stay healthy", 3),
            ("ÌñâÎ≥µÌïòÏÑ∏Ïöî", "Be happy", 3),
        ]
        
        for i, (korean, english, difficulty) in enumerate(intermediate_cases):
            test_cases.append(TestCase(
                id=f"intermediate_{i:03d}",
                korean_text=korean,
                expected_english=english,
                category="intermediate",
                difficulty=difficulty
            ))
        
        # Advanced sentence tests
        advanced_cases = [
            ("ÌïúÍµ≠ Î¨∏ÌôîÎäî Îß§Ïö∞ Ìù•ÎØ∏Î°≠Í≥† ÎèÖÌäπÌï©ÎãàÎã§", "Korean culture is very interesting and unique", 4),
            ("Í∏∞Ïà† Î∞úÏ†ÑÏúºÎ°ú Ïù∏Ìï¥ Ïö∞Î¶¨Ïùò ÏÇ∂Ïù¥ ÌÅ¨Í≤å Î≥ÄÌñàÏäµÎãàÎã§", "Our lives have changed significantly due to technological development", 5),
            ("ÌôòÍ≤Ω Î≥¥Ìò∏Îäî Ïö∞Î¶¨ Î™®ÎëêÏùò Ï±ÖÏûÑÏûÖÎãàÎã§", "Environmental protection is everyone's responsibility", 4),
            ("ÍµêÏú°ÏùÄ Í∞úÏù∏Ïùò ÎØ∏ÎûòÎ•º Î∞ùÍ≤å ÎßåÎì≠ÎãàÎã§", "Education brightens an individual's future", 4),
            ("Í±¥Í∞ïÏùÑ Ïú†ÏßÄÌïòÎäî Í≤ÉÏùÄ Îß§Ïö∞ Ï§ëÏöîÌï©ÎãàÎã§", "Maintaining health is very important", 4),
            ("ÏπúÍµ¨ÏôÄÏùò Í¥ÄÍ≥ÑÎ•º ÏÜåÏ§ëÌûà Ïó¨Í≤®Ïïº Ìï©ÎãàÎã§", "We should cherish relationships with friends", 4),
            ("ÎØ∏ÎûòÎ•º ÏúÑÌï¥ ÏßÄÍ∏à Î¨¥ÏóáÏùÑ Ìï¥Ïïº Ìï†ÏßÄ ÏÉùÍ∞ÅÌï¥Î¥ÖÏãúÎã§", "Let's think about what we should do now for the future", 5),
            ("Îã§Î•∏ Î¨∏ÌôîÎ•º Ïù¥Ìï¥ÌïòÎäî Í≤ÉÏùÄ Ï§ëÏöîÌïú Îä•Î†•ÏûÖÎãàÎã§", "Understanding different cultures is an important skill", 5),
            ("ÎÖ∏Î†• ÏóÜÏù¥Îäî ÏÑ±Í≥µÏùÑ Í∏∞ÎåÄÌï† Ïàò ÏóÜÏäµÎãàÎã§", "We cannot expect success without effort", 4),
            ("Îß§Ïùº Ï°∞Í∏àÏî© Î∞úÏ†ÑÌïòÎäî Í≤ÉÏù¥ Ï§ëÏöîÌï©ÎãàÎã§", "It's important to improve a little bit every day", 4),
        ]
        
        for i, (korean, english, difficulty) in enumerate(advanced_cases):
            test_cases.append(TestCase(
                id=f"advanced_{i:03d}",
                korean_text=korean,
                expected_english=english,
                category="advanced",
                difficulty=difficulty
            ))
        
        # Domain-specific tests
        domain_cases = [
            # Technology
            ("Ïù∏Í≥µÏßÄÎä• Í∏∞Ïà†Ïù¥ Îπ†Î•¥Í≤å Î∞úÏ†ÑÌïòÍ≥† ÏûàÏäµÎãàÎã§", "Artificial intelligence technology is developing rapidly", 4),
            ("Î®∏Ïã†Îü¨ÎãùÏùÄ Îç∞Ïù¥ÌÑ∞Î°úÎ∂ÄÌÑ∞ Ìå®ÌÑ¥ÏùÑ ÌïôÏäµÌï©ÎãàÎã§", "Machine learning learns patterns from data", 4),
            ("Îî•Îü¨Îãù Ïã†Í≤ΩÎßùÏùÄ Î≥µÏû°Ìïú Î¨∏Ï†úÎ•º Ìï¥Í≤∞Ìï©ÎãàÎã§", "Deep neural networks solve complex problems", 5),
            
            # Business
            ("ÏãúÏû• Ï°∞ÏÇ¨Îäî ÎπÑÏ¶àÎãàÏä§ Ï†ÑÎûµÏóê Ï§ëÏöîÌï©ÎãàÎã§", "Market research is important for business strategy", 4),
            ("Í≥†Í∞ù ÎßåÏ°±ÎèÑÎ•º ÎÜíÏù¥Îäî Í≤ÉÏù¥ Ïö∞ÏÑ†ÏûÖÎãàÎã§", "Increasing customer satisfaction is a priority", 4),
            ("Ìö®Í≥ºÏ†ÅÏù∏ ÎßàÏºÄÌåÖÏùÄ Î∏åÎûúÎìú Ïù∏ÏßÄÎèÑÎ•º ÎÜíÏûÖÎãàÎã§", "Effective marketing increases brand awareness", 4),
            
            # Healthcare
            ("Ï†ïÍ∏∞Ï†ÅÏù∏ Í±¥Í∞ï Í≤ÄÏßÑÏùÄ ÏßàÎ≥ëÏùÑ ÏòàÎ∞©Ìï©ÎãàÎã§", "Regular health checkups prevent diseases", 4),
            ("Í∑†Ìòï Ïû°Ìûå ÏãùÎã®ÏùÄ Í±¥Í∞ïÏóê ÌïÑÏàòÏ†ÅÏûÖÎãàÎã§", "A balanced diet is essential for health", 4),
            ("Ï∂©Î∂ÑÌïú ÏàòÎ©¥ÏùÄ Î©¥Ïó≠ Ï≤¥Í≥ÑÎ•º Í∞ïÌôîÌï©ÎãàÎã§", "Sufficient sleep strengthens the immune system", 4),
            
            # Education
            ("ÌèâÏÉù ÌïôÏäµÏùÄ ÌòÑÎåÄ ÏÇ¨ÌöåÏóêÏÑú Ï§ëÏöîÌï©ÎãàÎã§", "Lifelong learning is important in modern society", 4),
            ("Ï∞ΩÏùòÏ†Å ÏÇ¨Í≥†Îäî Î¨∏Ï†ú Ìï¥Í≤∞Ïóê ÎèÑÏõÄÏù¥ Îê©ÎãàÎã§", "Creative thinking helps in problem solving", 4),
            ("ÌòëÏóÖ Îä•Î†•ÏùÄ ÏßÅÏû•ÏóêÏÑú ÌïÑÏàòÏ†ÅÏûÖÎãàÎã§", "Collaboration skills are essential in the workplace", 4),
        ]
        
        for i, (korean, english, difficulty) in enumerate(domain_cases):
            domain = ["technology", "business", "healthcare", "education"][i // 3]
            test_cases.append(TestCase(
                id=f"domain_{domain}_{i%3:03d}",
                korean_text=korean,
                expected_english=english,
                category=f"domain_{domain}",
                difficulty=difficulty
            ))
        
        return test_cases
    
    def generate_test_images(self, test_cases: List[TestCase]) -> List[TestCase]:
        """Generate test images for visual translation testing."""
        print("Generating test images...")
        
        # Create images with Korean text
        for i, case in enumerate(test_cases[:20]):  # Generate images for first 20 cases
            # Create image with Korean text
            img = Image.new('RGB', (400, 200), color='white')
            draw = ImageDraw.Draw(img)
            
            # Try to use a font that supports Korean (fallback to default)
            try:
                font = ImageFont.truetype("malgun.ttf", 36)
            except:
                try:
                    font = ImageFont.truetype("arial.ttf", 36)
                except:
                    font = ImageFont.load_default()
            
            # Draw Korean text
            draw.text((50, 80), case.korean_text, fill='black', font=font)
            
            # Save image
            image_path = f"tests/comprehensive/data/image_{case.id}.png"
            img.save(image_path)
            
            # Update test case
            case.image_path = image_path
            
            if i % 5 == 0:
                print(f"  Generated {i+1}/{min(20, len(test_cases))} images")
        
        return test_cases
    
    def generate_test_audio(self, test_cases: List[TestCase]) -> List[TestCase]:
        """Generate test audio files for audio translation testing."""
        print("Generating test audio files...")
        
        # Generate synthetic audio (sine wave tones representing speech patterns)
        for i, case in enumerate(test_cases[:10]):  # Generate audio for first 10 cases
            # Create synthetic audio (this is a placeholder - in real implementation,
            # you would use text-to-speech)
            sample_rate = 16000
            duration = 2.0  # 2 seconds
            
            # Generate a simple tone pattern (placeholder for speech)
            t = np.linspace(0, duration, int(sample_rate * duration))
            
            # Create a pattern that varies with the text length
            freq_base = 200 + len(case.korean_text) * 10
            audio = np.sin(2 * np.pi * freq_base * t)
            
            # Add some modulation
            modulation = np.sin(2 * np.pi * 3 * t)
            audio = audio * (0.8 + 0.2 * modulation)
            
            # Fade in/out
            fade_samples = int(0.1 * sample_rate)
            fade_in = np.linspace(0, 1, fade_samples)
            fade_out = np.linspace(1, 0, fade_samples)
            audio[:fade_samples] *= fade_in
            audio[-fade_samples:] *= fade_out
            
            # Save audio file
            audio_path = f"tests/comprehensive/data/audio_{case.id}.wav"
            sf.write(audio_path, audio, sample_rate)
            
            # Update test case
            case.audio_path = audio_path
            
            if i % 3 == 0:
                print(f"  Generated {i+1}/{min(10, len(test_cases))} audio files")
        
        return test_cases
    
    def translate_text(self, korean_text: str) -> Tuple[str, float]:
        """Translate Korean text to English."""
        start_time = time.time()
        
        # Tokenize input
        src_tokens = self.tokenizer.encode(korean_text)
        src_tensor = torch.tensor([src_tokens], dtype=torch.long).to(self.device)
        
        # Generate translation using the model's autoregressive generation
        with torch.no_grad():
            # Use the model's forward method for inference
            logits = self.model(src_tensor)
            
            # The model returns the generated sequence directly
            predicted_tokens = logits.squeeze(0).tolist()
            
            # Remove BOS and EOS tokens
            if predicted_tokens and predicted_tokens[0] == 2:  # Remove BOS
                predicted_tokens = predicted_tokens[1:]
            
            # Remove everything after EOS token
            if 3 in predicted_tokens:  # EOS token
                eos_idx = predicted_tokens.index(3)
                predicted_tokens = predicted_tokens[:eos_idx]
            
            # Decode output
            english_text = self.tokenizer.decode(predicted_tokens)
        
        execution_time = time.time() - start_time
        return english_text, execution_time
    
    def evaluate_single_case(self, test_case: TestCase) -> Dict:
        """Evaluate a single test case."""
        # Text translation
        predicted_english, execution_time = self.translate_text(test_case.korean_text)
        
        # Calculate metrics
        bleu_score = self.bleu_metric.compute([predicted_english], [[test_case.expected_english]])
        
        # Calculate accuracy (exact match)
        exact_match = predicted_english.lower().strip() == test_case.expected_english.lower().strip()
        
        # Calculate semantic similarity (simple word overlap)
        pred_words = set(predicted_english.lower().split())
        expected_words = set(test_case.expected_english.lower().split())
        
        if len(expected_words) > 0:
            word_overlap = len(pred_words.intersection(expected_words)) / len(expected_words)
        else:
            word_overlap = 0.0
        
        return {
            'test_case_id': test_case.id,
            'korean_text': test_case.korean_text,
            'expected_english': test_case.expected_english,
            'predicted_english': predicted_english,
            'bleu_score': bleu_score,
            'exact_match': exact_match,
            'word_overlap': word_overlap,
            'execution_time': execution_time,
            'category': test_case.category,
            'difficulty': test_case.difficulty,
            'image_path': test_case.image_path,
            'audio_path': test_case.audio_path
        }
    
    def run_comprehensive_test(self, num_workers: int = 4) -> Dict:
        """Run the comprehensive test suite."""
        print("Starting comprehensive test suite...")
        start_time = time.time()
        
        # Generate test cases
        print("Generating test cases...")
        self.test_cases = self.generate_test_cases()
        self.test_cases = self.generate_test_images(self.test_cases)
        self.test_cases = self.generate_test_audio(self.test_cases)
        
        print(f"Total test cases: {len(self.test_cases)}")
        
        # Run tests in parallel
        print("Running translation tests...")
        results = []
        
        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            futures = [executor.submit(self.evaluate_single_case, case) for case in self.test_cases]
            
            for i, future in enumerate(futures):
                result = future.result()
                results.append(result)
                
                if (i + 1) % 10 == 0:
                    print(f"  Completed {i + 1}/{len(self.test_cases)} tests")
        
        # Calculate aggregate statistics
        total_time = time.time() - start_time
        
        # Calculate category-wise statistics
        category_stats = {}
        for category in ['basic', 'intermediate', 'advanced', 'domain_technology', 'domain_business', 'domain_healthcare', 'domain_education']:
            category_results = [r for r in results if r['category'] == category]
            if category_results:
                category_stats[category] = {
                    'count': len(category_results),
                    'avg_bleu': np.mean([r['bleu_score'] for r in category_results]),
                    'exact_match_rate': np.mean([r['exact_match'] for r in category_results]),
                    'avg_execution_time': np.mean([r['execution_time'] for r in category_results])
                }
        
        # Calculate difficulty-wise statistics
        difficulty_stats = {}
        for difficulty in range(1, 6):
            diff_results = [r for r in results if r['difficulty'] == difficulty]
            if diff_results:
                difficulty_stats[f'difficulty_{difficulty}'] = {
                    'count': len(diff_results),
                    'avg_bleu': np.mean([r['bleu_score'] for r in diff_results]),
                    'exact_match_rate': np.mean([r['exact_match'] for r in diff_results])
                }
        
        # Overall statistics
        overall_stats = {
            'total_tests': len(results),
            'overall_bleu': np.mean([r['bleu_score'] for r in results]),
            'overall_exact_match_rate': np.mean([r['exact_match'] for r in results]),
            'avg_execution_time': np.mean([r['execution_time'] for r in results]),
            'total_execution_time': total_time,
            'tests_per_second': len(results) / total_time
        }
        
        # Check if 99% target is achieved
        perfect_translation_rate = np.mean([r['exact_match'] for r in results])
        target_achieved = perfect_translation_rate >= 0.99
        
        comprehensive_results = {
            'overall_stats': overall_stats,
            'category_stats': category_stats,
            'difficulty_stats': difficulty_stats,
            'individual_results': results,
            'target_achieved': target_achieved,
            'perfect_translation_rate': perfect_translation_rate,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        self.results = comprehensive_results
        return comprehensive_results
    
    def generate_report(self, results: Dict, output_path: str = "tests/comprehensive/reports/comprehensive_test_report.html"):
        """Generate a comprehensive HTML report."""
        print("Generating comprehensive test report...")
        
        # Create visualizations
        self._create_visualizations(results)
        
        # Generate HTML report
        html_content = f"""
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Korean-English Translation Comprehensive Test Report</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }}
        .header {{ background-color: #f4f4f4; padding: 20px; border-radius: 5px; }}
        .summary {{ background-color: #e8f5e8; padding: 15px; border-radius: 5px; margin: 20px 0; }}
        .category-stats {{ display: flex; flex-wrap: wrap; gap: 20px; margin: 20px 0; }}
        .category-card {{ background-color: #f9f9f9; padding: 15px; border-radius: 5px; flex: 1; min-width: 200px; }}
        .results-table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        .results-table th, .results-table td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        .results-table th {{ background-color: #f2f2f2; }}
        .exact-match {{ background-color: #d4edda; }}
        .no-match {{ background-color: #f8d7da; }}
        .target-achieved {{ background-color: #28a745; color: white; padding: 10px; border-radius: 5px; text-align: center; }}
        .target-not-achieved {{ background-color: #dc3545; color: white; padding: 10px; border-radius: 5px; text-align: center; }}
        .charts {{ margin: 20px 0; }}
        .chart {{ margin: 20px 0; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>Korean-English Translation Comprehensive Test Report</h1>
        <p><strong>Test Date:</strong> {results['timestamp']}</p>
        <p><strong>Model:</strong> Optimized CVM Transformer</p>
        <p><strong>Total Test Cases:</strong> {results['overall_stats']['total_tests']}</p>
    </div>
    
    <div class="summary">
        <h2>Overall Performance Summary</h2>
        <p><strong>Average BLEU Score:</strong> {results['overall_stats']['overall_bleu']:.4f}</p>
        <p><strong>Perfect Translation Rate:</strong> {results['overall_stats']['overall_exact_match_rate']:.2%}</p>
        <p><strong>Average Execution Time:</strong> {results['overall_stats']['avg_execution_time']:.4f} seconds</p>
        <p><strong>Tests per Second:</strong> {results['overall_stats']['tests_per_second']:.2f}</p>
        
        <div class="{'target-achieved' if results['target_achieved'] else 'target-not-achieved'}">
            <h3>{'üéâ TARGET ACHIEVED! üéâ' if results['target_achieved'] else 'Target Not Achieved'}</h3>
            <p>Perfect Translation Rate: {results['perfect_translation_rate']:.2%} (Target: 99%)</p>
        </div>
    </div>
    
    <div class="charts">
        <h2>Performance Visualizations</h2>
        <div class="chart">
            <img src="category_performance.png" alt="Category Performance" style="max-width: 100%; height: auto;">
        </div>
        <div class="chart">
            <img src="difficulty_analysis.png" alt="Difficulty Analysis" style="max-width: 100%; height: auto;">
        </div>
        <div class="chart">
            <img src="bleu_distribution.png" alt="BLEU Score Distribution" style="max-width: 100%; height: auto;">
        </div>
    </div>
    
    <div class="category-stats">
        <h2>Category-wise Performance</h2>
        """
        
        for category, stats in results['category_stats'].items():
            html_content += f"""
        <div class="category-card">
            <h3>{category.replace('_', ' ').title()}</h3>
            <p><strong>Test Count:</strong> {stats['count']}</p>
            <p><strong>Avg BLEU:</strong> {stats['avg_bleu']:.4f}</p>
            <p><strong>Exact Match Rate:</strong> {stats['exact_match_rate']:.2%}</p>
            <p><strong>Avg Execution Time:</strong> {stats['avg_execution_time']:.4f}s</p>
        </div>
            """
        
        html_content += """
    </div>
    
    <h2>Individual Test Results</h2>
    <table class="results-table">
        <thead>
            <tr>
                <th>ID</th>
                <th>Category</th>
                <th>Difficulty</th>
                <th>Korean Text</th>
                <th>Expected English</th>
                <th>Predicted English</th>
                <th>BLEU Score</th>
                <th>Exact Match</th>
                <th>Execution Time</th>
            </tr>
        </thead>
        <tbody>
        """
        
        for result in results['individual_results']:
            row_class = 'exact-match' if result['exact_match'] else 'no-match'
            html_content += f"""
            <tr class="{row_class}">
                <td>{result['test_case_id']}</td>
                <td>{result['category']}</td>
                <td>{result['difficulty']}</td>
                <td>{result['korean_text']}</td>
                <td>{result['expected_english']}</td>
                <td>{result['predicted_english']}</td>
                <td>{result['bleu_score']:.4f}</td>
                <td>{'‚úì' if result['exact_match'] else '‚úó'}</td>
                <td>{result['execution_time']:.4f}s</td>
            </tr>
            """
        
        html_content += """
        </tbody>
    </table>
</body>
</html>
        """
        
        # Save HTML report
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"Comprehensive test report saved to: {output_path}")
    
    def _create_visualizations(self, results: Dict):
        """Create performance visualizations."""
        plt.style.use('seaborn-v0_8')
        
        # Category performance chart
        plt.figure(figsize=(12, 6))
        categories = list(results['category_stats'].keys())
        bleu_scores = [results['category_stats'][cat]['avg_bleu'] for cat in categories]
        exact_match_rates = [results['category_stats'][cat]['exact_match_rate'] * 100 for cat in categories]
        
        x = np.arange(len(categories))
        width = 0.35
        
        plt.bar(x - width/2, bleu_scores, width, label='BLEU Score', alpha=0.8)
        plt.bar(x + width/2, exact_match_rates, width, label='Exact Match Rate (%)', alpha=0.8)
        
        plt.xlabel('Category')
        plt.ylabel('Score')
        plt.title('Performance by Category')
        plt.xticks(x, [cat.replace('_', ' ').title() for cat in categories], rotation=45)
        plt.legend()
        plt.tight_layout()
        plt.savefig('tests/comprehensive/reports/category_performance.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # Difficulty analysis chart
        plt.figure(figsize=(10, 6))
        difficulties = list(results['difficulty_stats'].keys())
        bleu_by_diff = [results['difficulty_stats'][diff]['avg_bleu'] for diff in difficulties]
        exact_by_diff = [results['difficulty_stats'][diff]['exact_match_rate'] * 100 for diff in difficulties]
        
        x = np.arange(len(difficulties))
        
        plt.plot(x, bleu_by_diff, 'o-', label='BLEU Score', linewidth=2, markersize=8)
        plt.plot(x, exact_by_diff, 's-', label='Exact Match Rate (%)', linewidth=2, markersize=8)
        
        plt.xlabel('Difficulty Level')
        plt.ylabel('Score')
        plt.title('Performance vs Difficulty Level')
        plt.xticks(x, [f'Level {diff.split("_")[1]}' for diff in difficulties])
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig('tests/comprehensive/reports/difficulty_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # BLEU score distribution histogram
        plt.figure(figsize=(10, 6))
        bleu_scores = [r['bleu_score'] for r in results['individual_results']]
        
        plt.hist(bleu_scores, bins=20, alpha=0.7, edgecolor='black')
        plt.axvline(results['overall_stats']['overall_bleu'], color='red', linestyle='--', 
                   label=f'Mean BLEU: {results["overall_stats"]["overall_bleu"]:.4f}')
        plt.axvline(0.99, color='green', linestyle='--', label='Target: 0.99')
        
        plt.xlabel('BLEU Score')
        plt.ylabel('Frequency')
        plt.title('BLEU Score Distribution')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig('tests/comprehensive/reports/bleu_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("Visualizations created and saved")

def main():
    """Main function to run the comprehensive test suite."""
    print("=== Korean-English Translation Comprehensive Test Suite ===")
    
    # Initialize test suite
    model_path = "models/production/optimized_model.pth"
    tokenizer_path = "data/tokenizers/kr_en_diverse.model"
    
    if not Path(model_path).exists():
        print(f"Error: Model not found at {model_path}")
        print("Please run the optimized training first.")
        return
    
    if not Path(tokenizer_path).exists():
        print(f"Error: Tokenizer not found at {tokenizer_path}")
        print("Please ensure the tokenizer is trained.")
        return
    
    test_suite = ComprehensiveTestSuite(model_path, tokenizer_path)
    
    # Run comprehensive tests
    results = test_suite.run_comprehensive_test(num_workers=4)
    
    # Generate report
    test_suite.generate_report(results)
    
    # Save detailed results (convert numpy types to Python types)
    def convert_numpy_types(obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.bool_):
            return bool(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {k: convert_numpy_types(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_numpy_types(item) for item in obj]
        return obj
    
    with open('tests/comprehensive/results/detailed_results.json', 'w', encoding='utf-8') as f:
        json.dump(convert_numpy_types(results), f, ensure_ascii=False, indent=2)
    
    # Print summary
    print("\n" + "="*60)
    print("COMPREHENSIVE TEST SUMMARY")
    print("="*60)
    print(f"Total Tests: {results['overall_stats']['total_tests']}")
    print(f"Average BLEU Score: {results['overall_stats']['overall_bleu']:.4f}")
    print(f"Perfect Translation Rate: {results['overall_stats']['overall_exact_match_rate']:.2%}")
    print(f"Target (99%) Achieved: {'‚úÖ YES' if results['target_achieved'] else '‚ùå NO'}")
    print(f"Average Execution Time: {results['overall_stats']['avg_execution_time']:.4f} seconds")
    print(f"Tests per Second: {results['overall_stats']['tests_per_second']:.2f}")
    print("="*60)
    
    if results['target_achieved']:
        print("üéâ CONGRATULATIONS! 99% PERFECT TRANSLATION TARGET ACHIEVED! üéâ")
    else:
        improvement_needed = (0.99 - results['overall_stats']['overall_exact_match_rate']) / results['overall_stats']['overall_exact_match_rate'] * 100
        print(f"üìà Need {improvement_needed:.1f}% improvement to reach 99% target")
    
    print(f"\nüìä Detailed report saved to: tests/comprehensive/reports/comprehensive_test_report.html")
    print(f"üìã Detailed results saved to: tests/comprehensive/results/detailed_results.json")

if __name__ == "__main__":
    main()